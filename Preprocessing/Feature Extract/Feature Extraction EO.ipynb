{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad10c9f0-fd2f-43a7-ad76-aaa8cf980d92",
   "metadata": {},
   "source": [
    "# Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70f123a5-57c4-4753-823b-f40a7afe4436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import mne\n",
    "import pywt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import skew\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9d106a-06a1-4097-accf-06521f4842d7",
   "metadata": {},
   "source": [
    "# Data and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24a395ac-a2a9-46dc-9a03-976b79db53ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S1 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "16 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S10 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S11 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S12 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S13 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S14 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "8 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S16 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "13 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S17 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S18 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S19 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S2 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S20 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S21 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S22 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "13 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S23 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S24 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "13 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S26 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S27 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S28 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "13 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S29 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S3 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S30 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S4 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "13 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S5 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S6 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S7 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S8 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\H S9 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Healthy\\Healthy Eyes Open\\HS15EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S1  EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S10 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S11 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "13 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S12 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "8 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S13 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S14 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S15 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S16 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "13 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S17 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "13 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S18 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S19 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "13 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S2 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "13 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S20 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S21 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S22 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "13 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S23 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S24 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S25 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S26 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S27 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "13 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S28 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S29 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S3 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S30 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S31 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S32 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S33 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "13 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S34 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "13 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S4 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S5 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S6 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\khand\\MDD\\W.out Sep (train)\\New Workflow\\Preprocessing\\Feature Extract\\Windows_20s\\Non Healthy\\MDD Eyes Open\\MDD S9 EO_epo.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =    -199.22 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "14 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Not setting metadata\n",
      "831 matching events found\n",
      "No baseline correction applied\n",
      "X shape: (831, 20, 180)\n",
      "Y shape: (831,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khand\\AppData\\Local\\Temp\\ipykernel_6576\\2271547922.py:45: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  print(\"X shape:\", X.get_data().shape)\n"
     ]
    }
   ],
   "source": [
    "# Define the base directory containing the processed data\n",
    "base_dir = 'Windows_20s'\n",
    "\n",
    "# Define the list of conditions (e.g., Healthy and Non Healthy)\n",
    "conditions = ['Healthy', 'Non Healthy']\n",
    "\n",
    "# Define the list of tasks for each condition\n",
    "tasks = {\n",
    "    'Healthy': ['Healthy Eyes Open'],\n",
    "    'Non Healthy': ['MDD Eyes Open']\n",
    "}\n",
    "\n",
    "# Initialize lists to store epochs data, labels, and group information\n",
    "epochs_data = []\n",
    "labels = []\n",
    "group = []\n",
    "\n",
    "# Iterate over conditions and tasks to load epochs data\n",
    "for condition in conditions:\n",
    "    for task in tasks[condition]:\n",
    "        # Construct the path to the epochs data directory\n",
    "        epochs_dir = os.path.join(base_dir, condition, task)\n",
    "        # Check if the directory exists\n",
    "        if os.path.isdir(epochs_dir):\n",
    "            # List files in the directory with _epo.fif suffix\n",
    "            epochs_files = [os.path.join(epochs_dir, f) for f in os.listdir(epochs_dir) if f.endswith('_epo.fif')]\n",
    "            # Load epochs data from each file\n",
    "            for epoch_file in epochs_files:\n",
    "                epochs = mne.read_epochs(epoch_file)\n",
    "                # Pick EEG channels\n",
    "                epochs.pick_types(eeg=True)\n",
    "                # Append epochs data, labels, and group information\n",
    "                epochs_data.append(epochs)\n",
    "                labels.append(epochs.events[:, 2])\n",
    "                group.extend([len(labels) - 1] * len(epochs))\n",
    "        else:\n",
    "            print(f\"Directory not found: {epochs_dir}\")\n",
    "\n",
    "# Combine epochs data, labels, and group information\n",
    "X = mne.concatenate_epochs(epochs_data)\n",
    "Y = np.hstack(labels)\n",
    "group = np.array(group)\n",
    "# Now you can use X, Y, and group for further analysis\n",
    "# Print dimensions\n",
    "print(\"X shape:\", X.get_data().shape)\n",
    "print(\"Y shape:\", Y.shape)\n",
    "\n",
    "# Now you have concatenated \"Eyes Close\" epochs data in X and corresponding labels in Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a49bf9-fd9e-461c-bc45-3ca9cafbc21e",
   "metadata": {},
   "source": [
    "# Functions of Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32013f44-59d3-4900-8c43-bb04ec0c8a04",
   "metadata": {},
   "source": [
    "## Time Domain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1263ad5e-a2f9-47bd-98a5-bc6ba5d81fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "def zero_crossing_rate(signal):\n",
    "    zero_crossings = np.where(np.diff(np.sign(signal)))[0]\n",
    "    return len(zero_crossings) / len(signal)\n",
    "\n",
    "def hjorth_parameters(signal):\n",
    "    diff_input = np.diff(signal)\n",
    "    diff_diff_input = np.diff(diff_input)\n",
    "\n",
    "    activity = np.var(signal)\n",
    "    mobility = np.sqrt(np.var(diff_input)/activity)\n",
    "    complexity = np.sqrt(np.var(diff_diff_input)/np.var(diff_input)) / mobility\n",
    "\n",
    "    return activity, mobility, complexity\n",
    "\n",
    "def extract_time_domain_features(epochs):\n",
    "    features = []\n",
    "\n",
    "    for epoch in epochs:\n",
    "        epoch_features = []\n",
    "\n",
    "        for channel_data in epoch:\n",
    "            # Flatten the channel data\n",
    "            flattened_data = channel_data.flatten()\n",
    "\n",
    "            # Basic Time-Domain Features\n",
    "            mean_val = np.mean(flattened_data)\n",
    "            median_val = np.median(flattened_data)\n",
    "            var_val = np.var(flattened_data)\n",
    "            std_dev = np.std(flattened_data)\n",
    "            skewness = skew(flattened_data)\n",
    "            kurt = kurtosis(flattened_data)\n",
    "            zcr = zero_crossing_rate(flattened_data)\n",
    "            peak_amp = np.ptp(flattened_data)\n",
    "\n",
    "            # Hjorth Parameters\n",
    "            activity, mobility, complexity = hjorth_parameters(flattened_data)\n",
    "\n",
    "            # Additional Features\n",
    "            num_waves = len(find_peaks(flattened_data)[0])\n",
    "            wave_duration = len(flattened_data) / num_waves if num_waves > 0 else 0\n",
    "\n",
    "            channel_features = [\n",
    "                mean_val, median_val, var_val, std_dev, skewness, kurt, zcr, num_waves,\n",
    "                wave_duration, peak_amp, activity, mobility, complexity\n",
    "            ]\n",
    "            epoch_features.append(channel_features)\n",
    "\n",
    "        features.append(epoch_features)\n",
    "\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260b19cf-f12d-471b-b6a3-3f9798c25f5d",
   "metadata": {},
   "source": [
    "## Frequency Domain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2aebb562-a402-4499-9f10-7a4767edf870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import welch\n",
    "\n",
    "\n",
    "\n",
    "def get_wavelet_coeffs(channel_data, wavelet='db4', level=3):\n",
    "    coeffs = pywt.wavedec(channel_data, wavelet, level=level)\n",
    "    return coeffs\n",
    "\n",
    "\n",
    "def extract_frequency_domain_features(epochs, sfreq,wavelet='db4', bands={'delta': (1, 3), 'theta': (4, 7), 'alpha': (8, 12), 'beta': (13, 30), 'gamma': (31, 60), 'sigma': (11, 16)}):\n",
    "    features = []\n",
    "\n",
    "    for epoch in epochs:\n",
    "        epoch_features = []\n",
    "\n",
    "        for channel_data in epoch:\n",
    "            # Compute the Power Spectral Density (PSD)\n",
    "            freqs, psd = welch(channel_data, sfreq, nperseg=180)\n",
    "\n",
    "            # Frequency domain features\n",
    "            mean_val = np.mean(psd)\n",
    "            median_val = np.median(psd)\n",
    "            var_val = np.var(psd)\n",
    "            std_dev = np.std(psd)\n",
    "            skewness = skew(psd)\n",
    "            kurt = kurtosis(psd)\n",
    "\n",
    "            # Compute wavelet coefficients\n",
    "            wave_coeffs = get_wavelet_coeffs(channel_data, wavelet, level=3)\n",
    "            wave_coeffs_mean = np.mean(wave_coeffs[0])\n",
    "\n",
    "            # Band Power Features\n",
    "            band_powers = {}\n",
    "            for band, freq_range in bands.items():\n",
    "                freq_mask = (freqs >= freq_range[0]) & (freqs <= freq_range[1])\n",
    "                band_power = np.sum(psd[freq_mask])\n",
    "                band_powers[band] = band_power\n",
    "\n",
    "            # Band Power Ratios\n",
    "            theta_alpha_ratio = band_powers['theta'] / band_powers['alpha']\n",
    "            beta_alpha_ratio = band_powers['beta'] / band_powers['alpha']\n",
    "            theta_alpha_beta_ratio = (band_powers['theta'] + band_powers['alpha']) / band_powers['beta']\n",
    "            # Additional Band Power Ratios\n",
    "            theta_beta_ratio = band_powers['theta'] / band_powers['beta']\n",
    "            theta_alpha_beta_alpha_ratio = (band_powers['theta'] + band_powers['alpha']) / (band_powers['alpha'] + band_powers['beta'])\n",
    "            gamma_delta_ratio = band_powers['gamma'] / band_powers['delta']\n",
    "            gamma_beta_delta_alpha_ratio = (band_powers['gamma'] + band_powers['beta']) / (band_powers['delta'] + band_powers['alpha'])\n",
    "\n",
    "\n",
    "            channel_features = [\n",
    "                mean_val, median_val, var_val, std_dev, skewness, kurt,\n",
    "                band_powers['delta'], band_powers['theta'], band_powers['alpha'],\n",
    "                band_powers['beta'], band_powers['gamma'], band_powers['sigma'],\n",
    "                theta_alpha_ratio, beta_alpha_ratio, theta_alpha_beta_ratio,theta_beta_ratio,\n",
    "                theta_alpha_beta_alpha_ratio, gamma_delta_ratio, gamma_beta_delta_alpha_ratio,\n",
    "                wave_coeffs_mean\n",
    "            ]\n",
    "            epoch_features.append(channel_features)\n",
    "\n",
    "        features.append(epoch_features)\n",
    "\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e76d9c5-f176-4a1d-b848-941235788af2",
   "metadata": {},
   "source": [
    "## Descrete Wavelet Transform (DWT) Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f315483-84e9-4b89-afe4-3135fdb4c239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "\n",
    "def extract_dwt_features(epochs, wavelet='db4', level=4):\n",
    "   \n",
    "    n_epochs, n_channels, _ = epochs.shape\n",
    "    dwt_features = []\n",
    "\n",
    "    for epoch in epochs:\n",
    "        epoch_features = []\n",
    "        for channel in epoch:\n",
    "            # Perform DWT\n",
    "            coeffs = pywt.wavedec(channel, wavelet, level=level)\n",
    "            \n",
    "            # Concatenate DWT coefficients\n",
    "            concatenated_coeffs = np.concatenate(coeffs, axis=0)\n",
    "            \n",
    "            epoch_features.append(concatenated_coeffs)\n",
    "        \n",
    "        dwt_features.append(epoch_features)\n",
    "\n",
    "    return np.array(dwt_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab5379f-3697-45d5-ae2a-ec6c953fb2a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Detrended Flactuation Analysis (DFA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4cae3ae-1ab7-4de7-8fd3-7d14dfbbe245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dfa_features(epochs, min_window_size, max_window_size):\n",
    "    \n",
    "    n_epochs, n_channels, _ = epochs.shape\n",
    "    dfa_features = []\n",
    "\n",
    "    for epoch in epochs:\n",
    "        epoch_features = []\n",
    "        for channel in epoch:\n",
    "            channel_features = []\n",
    "            for w in range(min_window_size, max_window_size + 1):\n",
    "                # Compute DFA\n",
    "                dfa = compute_dfa(channel, w)\n",
    "                channel_features.append(dfa)\n",
    "            epoch_features.append(channel_features)\n",
    "        dfa_features.append(epoch_features)\n",
    "\n",
    "    return np.array(dfa_features)\n",
    "\n",
    "def compute_dfa(data, window_size):\n",
    "    \"\"\"Compute Detrended Fluctuation Analysis (DFA) for a single channel.\"\"\"\n",
    "    # Compute cumulative sum of the data\n",
    "    cumsum = np.cumsum(data - np.mean(data))\n",
    "\n",
    "    # Divide the signal into non-overlapping windows of size window_size\n",
    "    windows = np.array_split(cumsum, len(data) // window_size)\n",
    "\n",
    "    # Compute the local trend within each window\n",
    "    trends = [np.polyfit(np.arange(len(window)), window, 1)[0] for window in windows]\n",
    "\n",
    "    # Compute the root mean square of the integrated fluctuation within each window\n",
    "    flucts = np.array([np.sqrt(np.mean((window - trend) ** 2)) for window, trend in zip(windows, trends)])\n",
    "\n",
    "    # Compute the DFA value as the slope of the log-log plot of window size vs. fluctuation\n",
    "    dfa = np.polyfit(np.log(np.arange(len(flucts)) + 1), np.log(flucts), 1)[0]\n",
    "\n",
    "    return dfa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7645884-cae2-47a4-a1b2-231237dc7164",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Higuchi's Fractual Dimension (HFD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "924873e1-2fe7-4906-937d-1d057308a365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hfd_features(epochs, kmax):\n",
    "   \n",
    "    n_epochs, n_channels, _ = epochs.shape\n",
    "    hfd_features = []\n",
    "\n",
    "    for epoch in epochs:\n",
    "        epoch_features = []\n",
    "        for channel in epoch:\n",
    "            channel_features = []\n",
    "            for k in range(2, kmax+1):\n",
    "                # Compute Higuchi's Fractal Dimension\n",
    "                hfd = compute_hfd(channel, k)\n",
    "                channel_features.append(hfd)\n",
    "            epoch_features.append(channel_features)\n",
    "        hfd_features.append(epoch_features)\n",
    "\n",
    "    return np.array(hfd_features)\n",
    "\n",
    "\n",
    "def compute_hfd(data, kmax):\n",
    "    \"\"\"Compute Higuchi's Fractal Dimension for a single channel.\"\"\"\n",
    "    n = len(data)\n",
    "    lk = np.zeros(kmax)\n",
    "\n",
    "    for k in range(2, kmax + 1):\n",
    "        lmk = 0.0\n",
    "        for m in range(1, k + 1):\n",
    "            lk_m_sum = 0.0\n",
    "            for i in range(1, int(np.floor((n - m) / k)) + 1):\n",
    "                lk_m_sum += abs(data[m + i * k - 1] - data[m + (i - 1) * k - 1])\n",
    "            lk_m_sum *= (n - 1) / (k * np.floor((n - m) / k))\n",
    "            lmk += lk_m_sum / ((n - 1) / k)\n",
    "        lmk /= k\n",
    "        lk[k - 1] = lmk\n",
    "\n",
    "    return np.log(lk) / np.log(np.arange(2, kmax + 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdca61d2-3fa0-4295-a70f-dd80665d6ed9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Lemple - Ziv Complexity (LZC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38487322-8177-4554-8e26-b5593fe62820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lzc_features(epochs):\n",
    "    n_epochs, n_channels, _ = epochs.shape\n",
    "    lzc_features = []\n",
    "\n",
    "    for epoch in epochs:\n",
    "        epoch_features = []\n",
    "        for channel in epoch:\n",
    "            # Compute LZC for each channel\n",
    "            lzc = compute_lzc(channel)\n",
    "            epoch_features.append(lzc)\n",
    "        lzc_features.append(epoch_features)\n",
    "\n",
    "    return np.array(lzc_features)\n",
    "\n",
    "\n",
    "def compute_lzc(data):\n",
    "    \"\"\"Compute Lempel-Ziv Complexity (LZC) for a single channel.\"\"\"\n",
    "    n = len(data)\n",
    "    u = [data[0]]\n",
    "    complexity = 1\n",
    "\n",
    "    for i in range(1, n):\n",
    "        w = data[i]\n",
    "        if w not in u:\n",
    "            u.append(w)\n",
    "            complexity += 1\n",
    "\n",
    "    return complexity / n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104f9c1f-bd2e-4713-abd3-86544a9462b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Power Spectral Density (PSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d70e1cef-90e1-4047-9e2e-323a3f7b2f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import welch\n",
    "\n",
    "def extract_psd_features(epochs, sfreq):\n",
    "    psd_features = []\n",
    "    \n",
    "    for epoch in epochs:\n",
    "        epoch_features = []\n",
    "        \n",
    "        for channel_data in epoch:\n",
    "            # Compute Power Spectral Density (PSD)\n",
    "            freqs, psd = welch(channel_data, fs=sfreq)\n",
    "            \n",
    "            # Integrate PSD over frequency bands\n",
    "            delta_power = np.trapz(psd[(freqs >= 0.5) & (freqs <= 4)], x=freqs[(freqs >= 0.5) & (freqs <= 4)])\n",
    "            theta_power = np.trapz(psd[(freqs > 4) & (freqs <= 8)], x=freqs[(freqs > 4) & (freqs <= 8)])\n",
    "            alpha_power = np.trapz(psd[(freqs > 8) & (freqs <= 13)], x=freqs[(freqs > 8) & (freqs <= 13)])\n",
    "            beta_power = np.trapz(psd[(freqs > 13) & (freqs <= 30)], x=freqs[(freqs > 13) & (freqs <= 30)])\n",
    "            gamma_power = np.trapz(psd[(freqs > 30) & (freqs <= 100)], x=freqs[(freqs > 30) & (freqs <= 100)])\n",
    "            \n",
    "            # Total power\n",
    "            total_power = np.trapz(psd, x=freqs)\n",
    "            \n",
    "            epoch_features.append([delta_power, theta_power, alpha_power, beta_power, gamma_power, total_power])\n",
    "        \n",
    "        psd_features.append(epoch_features)\n",
    "    \n",
    "    return np.array(psd_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5b7998-aaf7-428f-882e-a0ace0c78e4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Spectral Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4c31be0-2a8e-43d1-9d98-631b2a8501e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entropy_features(epochs):\n",
    "    entropy_features = []\n",
    "    \n",
    "    for epoch in epochs:\n",
    "        epoch_features = []\n",
    "        \n",
    "        for channel_data in epoch:\n",
    "            # Compute power spectral density\n",
    "            freqs, psd = welch(channel_data)\n",
    "            \n",
    "            # Normalize PSD\n",
    "            psd /= np.sum(psd)\n",
    "            \n",
    "            # Compute Shannon entropy\n",
    "            entropy_val = -np.sum(psd * np.log2(psd))\n",
    "            epoch_features.append(entropy_val)\n",
    "        \n",
    "        entropy_features.append(epoch_features)\n",
    "    \n",
    "    return np.array(entropy_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c5aa28-96a6-4838-99f1-63a9143d4dfe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Statistical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2457b84-7efb-49ca-8139-7d905ab52d5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e1bab47-d935-49a9-9820-292e14f370ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mean_features(epochs):\n",
    "    mean_features = []\n",
    "    \n",
    "    for epoch in epochs:\n",
    "        epoch_features = []\n",
    "        \n",
    "        for channel_data in epoch:\n",
    "            # Compute mean value\n",
    "            mean_val = np.mean(channel_data)\n",
    "            epoch_features.append(mean_val)\n",
    "        \n",
    "        mean_features.append(epoch_features)\n",
    "    \n",
    "    return np.array(mean_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e949a275-1941-4a27-a6a3-46c41b9e48d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fe38598-6af9-481b-8649-d4764e398290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_variance_features(epochs):\n",
    "    variance_features = []\n",
    "    \n",
    "    for epoch in epochs:\n",
    "        epoch_features = []\n",
    "        \n",
    "        for channel_data in epoch:\n",
    "            # Compute variance\n",
    "            var_val = np.var(channel_data)\n",
    "            epoch_features.append(var_val)\n",
    "        \n",
    "        variance_features.append(epoch_features)\n",
    "    \n",
    "    return np.array(variance_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32230a0e-5505-4ab6-a341-ce7bdb1dddf8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87dc9337-4bf0-4570-9ddd-05fdf59993de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_skewness_features(epochs):\n",
    "    skewness_features = []\n",
    "    \n",
    "    for epoch in epochs:\n",
    "        epoch_features = []\n",
    "        \n",
    "        for channel_data in epoch:\n",
    "            # Compute skewness\n",
    "            skew_val = skew(channel_data)\n",
    "            epoch_features.append(skew_val)\n",
    "        \n",
    "        skewness_features.append(epoch_features)\n",
    "    \n",
    "    return np.array(skewness_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeb32dd-8a25-482a-973f-198ca8872172",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Continuous Wavelet Transform (CWT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0072e29-6942-48b3-be49-96f32579f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "\n",
    "def extract_cwt_features(epochs, wavelet='morl', scales=np.arange(1, 128)):\n",
    "    n_epochs, n_channels, _ = epochs.shape\n",
    "    cwt_features = []\n",
    "\n",
    "    for epoch in epochs:\n",
    "        epoch_cwt_features = []\n",
    "        \n",
    "        for channel in epoch:\n",
    "            # Perform CWT\n",
    "            cwt_coeffs, _ = pywt.cwt(channel, scales, wavelet)\n",
    "            epoch_cwt_features.append(cwt_coeffs)\n",
    "\n",
    "        cwt_features.append(epoch_cwt_features)\n",
    "\n",
    "    return np.array(cwt_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bec5b0-f5a0-4b50-8ef5-b0748e3a366b",
   "metadata": {},
   "source": [
    "# Extract and Save Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264c3ad8-5751-44c5-8ad1-b7d38c15b301",
   "metadata": {},
   "source": [
    "## Time Domain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4f4fd5c-a7df-4a49-bbf0-a11b419a9d7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_time = extract_time_domain_features(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13dc7964-3e7e-43b0-ac78-ba8f40b0610a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the file path to save the features\n",
    "save_path = 'eo_time.npz'\n",
    "\n",
    "# # Save the features\n",
    "np.savez(save_path, X_time=X_time)\n",
    "\n",
    "print(\"Features saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b31617-6bd5-4fa1-a01d-848034bea551",
   "metadata": {},
   "source": [
    "## Frequency Domain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e3daf77-3bda-410d-ac6f-b1bc580653dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sfreq = 256  # Replace with the sampling frequency of your data\n",
    "# epochs_data = [epoch.get_data() for epoch in epochs] \n",
    "X_frequency = extract_frequency_domain_features(X, sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32c4db47-b084-48d1-849e-a417873d4f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the file path to save the features\n",
    "save_path = 'eo_freq.npz'\n",
    "\n",
    "# Save the features\n",
    "np.savez(save_path, X_frequency=X_frequency)\n",
    "\n",
    "print(\"Features saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bb079e-293c-43cc-bffd-f7c9da1bdf2d",
   "metadata": {},
   "source": [
    "## DWT Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "157f96c6-199a-4518-9932-956b876689ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khand\\AppData\\Local\\Temp\\ipykernel_6576\\2738540519.py:2: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X_dwt = extract_dwt_features(X.get_data())\n"
     ]
    }
   ],
   "source": [
    "# Extract DWT features\n",
    "X_dwt = extract_dwt_features(X.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5029c74b-5739-42f7-b9f9-b9261cf45c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the file path to save the features\n",
    "save_path = 'eo_dwt.npz'\n",
    "\n",
    "# Save the features\n",
    "np.savez(save_path, X_dwt=X_dwt)\n",
    "\n",
    "print(\"Features saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2d2f4a-e056-48eb-950b-898c129a622b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## DFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38d85ad5-75d3-4288-af19-68897b6dac57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2984\\2949197905.py:3: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  max_window_size = int(np.log2(X.get_data().shape[2]))\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2984\\2949197905.py:6: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X_dfa = extract_dfa_features(X.get_data(), min_window_size, max_window_size)\n"
     ]
    }
   ],
   "source": [
    "# Define the minimum and maximum window sizes\n",
    "min_window_size = 2  # Since each epoch is 1 second long\n",
    "max_window_size = int(np.log2(X.get_data().shape[2]))\n",
    "\n",
    "# Extract DFA features\n",
    "X_dfa = extract_dfa_features(X.get_data(), min_window_size, max_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4837f31a-3836-4bad-94ea-59f628126496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the file path to save the features\n",
    "save_path = 'eo_dfa.npz'\n",
    "\n",
    "# Save the features\n",
    "np.savez(save_path, X_dfa=X_dfa)\n",
    "\n",
    "print(\"Features saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84712bb6-c63d-4cf2-b35e-e911b01fd365",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## HFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503bb6e4-6cba-4445-8479-92f0dce61386",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_716\\1036302989.py:4: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X_hfd = extract_hfd_features(X.get_data(), kmax)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_716\\1668856596.py:36: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(lk) / np.log(np.arange(2, kmax + 2))\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_716\\1668856596.py:31: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  lk_m_sum *= (n - 1) / (k * np.floor((n - m) / k))\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_716\\1668856596.py:31: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  lk_m_sum *= (n - 1) / (k * np.floor((n - m) / k))\n"
     ]
    }
   ],
   "source": [
    "sfreq = 256\n",
    "kmax = sfreq//2\n",
    "# Extract Higuchi's Fractal Dimension features\n",
    "X_hfd = extract_hfd_features(X.get_data(), kmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217432df-e2c9-4db3-82a5-80447c778906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path to save the features\n",
    "save_path = 'eo_hfd.npz'\n",
    "\n",
    "# Save the features\n",
    "np.savez(save_path, X_hfd=X_hfd)\n",
    "\n",
    "print(\"Features saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72c8303-adfd-4814-8f37-dd75783fa6d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LZC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3ca7cb0-5d45-4de6-87fe-4a02b253acdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_31440\\1568084668.py:2: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X_lzc = extract_lzc_features(X.get_data())\n"
     ]
    }
   ],
   "source": [
    "# Extract LZC features\n",
    "X_lzc = extract_lzc_features(X.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ec1301f-0cdf-4443-a050-3ff0be5d8b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the file path to save the features\n",
    "save_path = 'eo_lzc.npz'\n",
    "\n",
    "# Save the features\n",
    "np.savez(save_path, X_lzc=X_lzc)\n",
    "\n",
    "print(\"Features saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629ace17-5f3e-4557-a29d-659d71aeb722",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "435a1f45-c566-462c-91c3-e1f1cc434f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_31440\\3757737867.py:5: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X_psd = extract_psd_features(X.get_data(), sfreq)\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\mne\\Lib\\site-packages\\scipy\\signal\\_spectral_py.py:589: UserWarning: nperseg = 256 is greater than input length  = 180, using nperseg = 180\n",
      "  freqs, _, Pxy = _spectral_helper(x, y, fs, window, nperseg, noverlap,\n"
     ]
    }
   ],
   "source": [
    "# Define the sampling frequency\n",
    "sfreq = 256\n",
    "\n",
    "# Extract spectral features\n",
    "X_psd = extract_psd_features(X.get_data(), sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb7ba4b3-d2ae-42f7-a680-777fb2247ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the file path to save the features\n",
    "save_path = 'eo_psd.npz'\n",
    "\n",
    "# Save the features\n",
    "np.savez(save_path, X_psd=X_psd)\n",
    "\n",
    "print(\"Features saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c38381d-6650-4189-9bcc-1023d7756254",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Spectral Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02aeed63-281c-459c-8c37-ac7122d80e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_31440\\1377404312.py:1: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X_entropy = extract_entropy_features(X.get_data())\n"
     ]
    }
   ],
   "source": [
    "X_entropy = extract_entropy_features(X.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e40688f-222e-4fe9-9da1-a75a23d7f610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the file path to save the features\n",
    "save_path = 'eo_entropy.npz'\n",
    "\n",
    "# Save the features\n",
    "np.savez(save_path, X_entropy=X_entropy)\n",
    "\n",
    "print(\"Features saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc06fba-7f00-40a4-abe7-ed49770441c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Statistical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815346e7-f70b-45ca-be6e-66172b965e5c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0bbd3bf-9c6d-42d2-b336-7aea1bdccaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_31440\\730594860.py:1: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X_mean = extract_mean_features(X.get_data())\n"
     ]
    }
   ],
   "source": [
    "X_mean = extract_mean_features(X.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "073f1f8c-7bcf-4a70-bd6e-98dc39d61d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the file path to save the features\n",
    "save_path = 'eo_mean.npz'\n",
    "\n",
    "# Save the features\n",
    "np.savez(save_path, X_mean=X_mean)\n",
    "\n",
    "print(\"Features saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c2115e-10fa-44df-8072-a4e5b0a32358",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75021ea8-2256-41b8-8c21-6645f5adef80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_31440\\1504960069.py:1: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X_variance = extract_variance_features(X.get_data())\n"
     ]
    }
   ],
   "source": [
    "X_variance = extract_variance_features(X.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da5ce3c1-ef87-434a-83be-ab52a99c3c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the file path to save the features\n",
    "save_path = 'eo_variance.npz'\n",
    "\n",
    "# Save the features\n",
    "np.savez(save_path, X_variance=X_variance)\n",
    "\n",
    "print(\"Features saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24af849d-8924-4243-93b4-e236787c87e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "790f7c50-1738-4787-9b09-d8ea2f4aa5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_31440\\4238270862.py:1: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X_skewness = extract_skewness_features(X.get_data())\n"
     ]
    }
   ],
   "source": [
    "X_skewness = extract_skewness_features(X.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9eb51d34-dbe6-4e79-b0a9-09ea839908d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the file path to save the features\n",
    "save_path = 'eo_skewness.npz'\n",
    "\n",
    "# Save the features\n",
    "np.savez(save_path, X_skewness=X_skewness)\n",
    "\n",
    "print(\"Features saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249af165-edd9-43b5-a25c-d9cb0b2db0ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CWT Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbb6925-369a-49ab-8ae2-d8e3e0a69b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract CWT features\n",
    "# X_cwt = extract_cwt_features(X.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e963c77-6495-4bec-b811-7304e4cf10f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the file path to save the features\n",
    "# save_path = 'eo_cwt.npz'\n",
    "\n",
    "# # Save the features\n",
    "# np.savez(save_path, X_cwt=X_cwt)\n",
    "\n",
    "# print(\"Features saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc013a33-cbd2-44c0-b06f-6f6cee0ee624",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Complete"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
